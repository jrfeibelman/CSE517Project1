{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkgradHingeAndRidge(f, X, e, x, y,lambdaa):\n",
    "# % checkgradHingeAndRidge checks the derivatives in a hinge or ridge function, by comparing them to finite\n",
    "# % differences approximations. The partial derivatives and the approximation\n",
    "# % are printed and the norm of the difference divided by the norm of the sum is\n",
    "# % returned as an indication of accuracy.\n",
    "# %\n",
    "# % usage: checkgradHingeAndRidge('f', X, e, x, y,lambdaa)\n",
    "# %\n",
    "# % where X is the argument and e is the small perturbation used for the finite\n",
    "# % differences. and the x, y,lambdaa are parameters which\n",
    "# % get passed to hinge or ridge function. The function hinge or ridge function should be of the type\n",
    "# %\n",
    "# % fX, dfX = hinge(X, x, y,lambdaa) or fX, dfX = ridge(X, x, y,lambdaa)\n",
    "# %\n",
    "# % where fX is the function value and dfX is a vector of partial derivatives.\n",
    "# %\n",
    "# % Carl Edward Rasmussen, 2001-08-01.\n",
    "\n",
    "\n",
    "    y0,dy = f(X,x,y,lambdaa)   # get the partial derivatives dy\n",
    "    dh = np.zeros((len(X),1))\n",
    "    for j in range(len(X)):\n",
    "        dx = np.zeros((len(X),1))\n",
    "        dx[j] = dx[j] + e                            # perturb a single dimension\n",
    "        y2,dy2 = f(X+dx,x,y,lambdaa)\n",
    "        dx = -dx\n",
    "        y1,dy1 = f(X+dx,x,y,lambdaa)\n",
    "        dh[j] = (y2 - y1)/(2*e)\n",
    "\n",
    "    # dh (the gradient calculated by the finite difference method) should be almost the same as dy (the gradient calculated by your function)\n",
    "    # print(\"dh:\", dh)\n",
    "    # print(\"dy:\", dy)\n",
    "\n",
    "    d = np.linalg.norm(dh-dy)/np.linalg.norm(dh+dy);       # return norm of diff divided by norm of sum\n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(w,xTr,yTr,lambdaa):\n",
    "#\n",
    "# INPUT:\n",
    "# w weight vector (default w=0)\n",
    "# xTr:dxn matrix (each column is an input vector)\n",
    "# yTr:1xn matrix (each entry is a label)\n",
    "# lambdaa: regression constant\n",
    "#\n",
    "# OUTPUTS:\n",
    "# loss = the total loss obtained with w on xTr and yTr\n",
    "# gradient = the gradient at w\n",
    "#\n",
    "# [d,n]=size(xTr);\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    loss = (((xTr.transpose() @ w) - yTr)**2).sum() + lambdaa * (w.transpose() @ w)\n",
    "    gradient = 2 * (((xTr.transpose() @ w) - yTr) @ xTr.transpose()).sum() + 2 * lambdaa * w\n",
    "\n",
    "    return loss,gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linearmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7b8ba12ad298>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckgradHingeAndRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/stockalyzer/CSE517/CSE517Project1/checkgradHingeAndRidge.py\u001b[0m in \u001b[0;36mcheckgradHingeAndRidge\u001b[0;34m(f, X, e, x, y, lambdaa)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambdaa\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# get the partial derivatives dy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stockalyzer/CSE517/CSE517Project1/ridge.py\u001b[0m in \u001b[0;36mridge\u001b[0;34m(w, xTr, yTr, lambdaa)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinearmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambdaa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinearmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxTr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambdaa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linearmodel' is not defined"
     ]
    }
   ],
   "source": [
    "N=50\n",
    "D=5\n",
    "x=np.concatenate((np.random.randn(D,N),np.random.randn(D,N)+2),axis=1)\n",
    "y=np.concatenate((np.ones((1,N)),-np.ones((1,N))),axis=1)\n",
    "d=checkgradHingeAndRidge(ridge,np.random.rand(D, 1), 1e-05, x,y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Test 1\n",
      "\n",
      "Completed Test 1\n",
      "\n",
      "Starting Test 4\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'linearmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dd8e14a64efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mfailed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_tests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of failed example tests: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of passed example tests: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-dd8e14a64efa>\u001b[0m in \u001b[0;36mexample_tests\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Test 4\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m#Test 4: testing gradient of ridge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckgradHingeAndRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mfailtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e-10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stockalyzer/CSE517/CSE517Project1/checkgradHingeAndRidge.py\u001b[0m in \u001b[0;36mcheckgradHingeAndRidge\u001b[0;34m(f, X, e, x, y, lambdaa)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambdaa\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# get the partial derivatives dy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/stockalyzer/CSE517/CSE517Project1/ridge.py\u001b[0m in \u001b[0;36mridge\u001b[0;34m(w, xTr, yTr, lambdaa)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambdaa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myTr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mxTr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambdaa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linearmodel' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from logistic import logistic\n",
    "from ridge import ridge\n",
    "from checkgradLogistic import checkgradLogistic\n",
    "from checkgradHingeAndRidge import checkgradHingeAndRidge\n",
    "\n",
    "def example_tests():\n",
    "# % def example_tests():\n",
    "# %\n",
    "# % Tests for the SRM project. Some few example tests are implemented.\n",
    "# % Some are only dewscribed in the comments. You will have to implement\n",
    "# % those yourself.\n",
    "# %\n",
    "# % Output:\n",
    "# % r:    number of tests that broke\n",
    "# % ok:   number of passed tests\n",
    "# % s:    statement describing the failed test (s={} if all succeed)\n",
    "\n",
    "\n",
    "    random.seed(31415926535)\n",
    "    # % initial outputs\n",
    "    r=0\n",
    "    ok=0\n",
    "    s=[]  #used to be matlab cell array\n",
    "\n",
    "    # data set\n",
    "    N=50\n",
    "    D=5\n",
    "\n",
    "    x=np.concatenate((np.random.randn(D,N),np.random.randn(D,N)+2),axis=1)\n",
    "    y=np.concatenate((np.ones((1,N)),-np.ones((1,N))),axis=1)\n",
    "\n",
    "    print ('Starting Test 1\\n')\n",
    "    #Test 1: testing gradient of logistic\n",
    "    d=checkgradLogistic(logistic,np.random.rand(D,1),1e-05,x,y)\n",
    "    failtest = d>1e-10\n",
    "\n",
    "    if failtest:\n",
    "        r=r+1\n",
    "        s.append('Test 1: Logistic function does not pass checkgrad.')\n",
    "    else:\n",
    "        ok=ok+1;\n",
    "\n",
    "    print('Completed Test 1\\n')\n",
    "\n",
    "#     %% Test 2: logistic sanity check #1\n",
    "#     % we will test logistic with an all zeros weight vector, a random datapoint\n",
    "#     % and a random label in {-1,1}. The expected outcome is (very close to) log(2).\n",
    "\n",
    "#     print('Starting Test 3\\n')\n",
    "#     #Test 3: logistic sanity check #2\n",
    "#     w=np.random.rand(5,1)\n",
    "#     logistic_loss = logistic(w,x[:,1].reshape((5,1)),np.ones((1,1)))[0]\n",
    "#     failtest = np.abs(w.T.dot(x[:,1])+math.log(math.exp(logistic_loss)-1)) > 2.2204e-15\n",
    "#     if failtest:\n",
    "#         r=r+1\n",
    "#         s.append('Test 3: Logistic function does not pass sanity check #2.')\n",
    "#     else:\n",
    "#         ok=ok+1\n",
    "#     print('Completed Test 3\\n')\n",
    "\n",
    "\n",
    "    print('Starting Test 4\\n')\n",
    "    #Test 4: testing gradient of ridge\n",
    "    d = checkgradHingeAndRidge(ridge,np.random.rand(D, 1), 1e-05, x,y,10)\n",
    "    failtest = d > 1e-10\n",
    "\n",
    "    if failtest:\n",
    "        r = r+1\n",
    "        s.append('Test 4: Ridge function does not pass checkgrad.')\n",
    "    else:\n",
    "        ok=ok+1\n",
    "    print('Completed Test 4\\n')\n",
    "\n",
    "#     %% Test 5: testing gradient of hinge\n",
    "#     % we will test hinge using checkgrad on randomly generated x and y data\n",
    "#     % initializing w with 1e-05 and lambda with 1e-05. The gradient is supposed\n",
    "#     % to be smaller than 5e-07.\n",
    "#\n",
    "#\n",
    "#     %% Test 6: checking gradient descent\n",
    "#     % we will check grdescent using the squared loss, randomly generated input\n",
    "#     % weights and stepsize=1e-05, maxiter=1000,and tolerance=1e-09. The\n",
    "#     % norm of the gradient at the optimal solution should be zero (< 1e-05).\n",
    "#\n",
    "#\n",
    "#     %% Tests 7-12: solutions of hinge, ridge, and logistic\n",
    "#     % we will compare the solutions (loss value and gradient) of hinge,\n",
    "#     % ridge, and logistic to our implementation using x and y.\n",
    "#     % Note that you cannot implement those tests.\n",
    "\n",
    "    return r,ok,s\n",
    "\n",
    "def squaredloss(w,x,y):\n",
    "    [d,n]=np.shape(x)\n",
    "    diff=(w.T.dot(x)-y)\n",
    "    gradient=2*x.dot(diff.T)/n\n",
    "    loss = np.mean(diff**2)\n",
    "    return loss,gradient\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    failed,ok,msgs = example_tests()\n",
    "    print(\"Number of failed example tests: \"+str(failed))\n",
    "    print(\"Number of passed example tests: \"+str(ok))\n",
    "    if len(msgs):\n",
    "        failMsg = 'Unfortunately, you failed %d test(s) on this evaluation: \\n\\n' % len(msgs)\n",
    "        for j in range(0,len(msgs)):\n",
    "            print(msgs[j])\n",
    "    print(\"\\nNote: we only implemented 3 out of 12 tests for you. Check the inline documentation for what the other tests do and implement them yourself!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
